# -*- coding: utf-8 -*-
"""TCC - Aprendizado de maquina Compósitos - FINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bmaxFWeC6xBBDyvjLAhj3bn_b4F2FJeS
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression as LR
from sklearn.tree import DecisionTreeRegressor as DTR
from sklearn.ensemble import RandomForestRegressor as RFR
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
import sklearn.metrics as metrics
import numpy as np
from sklearn.model_selection import cross_val_predict, cross_val_score, KFold
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping
from keras.layers import Dense
from keras.utils.vis_utils import plot_model

"""#Importando Dados

##Dados Homogeneização Assimptótica 

Importado os dados gerados pelo método da homogeneização assintótica.
"""

root_path = os.getcwd()
dados_gerados_path=os.path.join(root_path,"Banco de Dados","Teste")

df=pd.read_csv(dados_gerados_path)
df

"""###Separando em X e y"""

X=df.iloc[:,0:8]
X

y_E1=df.iloc[:,8]
y_E2=df.iloc[:,9]
y_G12=df.iloc[:,10]
y_G23=df.iloc[:,11]
y_nu12=df.iloc[:,12]

y_NNW=df.iloc[:,8:]

"""Realizando a divisão entre treino e teste nos dados gerados."""

X_train,X_test,y_E1_train,y_E1_test,y_E2_train,y_E2_test,y_G12_train,y_G12_test,y_G23_train,y_G23_test,y_nu12_train,y_nu12_test,y_NNW_train,y_NNW_test=train_test_split(X,y_E1,y_E2,y_G12,y_G23,y_nu12,y_NNW,
                                                     train_size=0.8,random_state=2)

"""##Dados Reais

Importando os dados experimentais dos artigos.
"""

dados_reais_path=os.path.join(root_path,"Banco de Dados","dados elasticos_v6c.xlsx")

df_real_lamina=pd.read_excel(dados_reais_path,sheet_name='lamina')
df_real_lamina=df_real_lamina.drop(['Unnamed: 0','Unnamed: 1','Unnamed: 11','lamina.1','Reference','Vv','nu23'],axis=1)
df_real_lamina

df_real_fibra=pd.read_excel(dados_reais_path,sheet_name='fibra')
df_real_fibra=df_real_fibra.drop(['Unnamed: 0','Unnamed: 8','nu23f'],axis=1)
df_real_fibra

df_real_matriz=pd.read_excel(dados_reais_path,sheet_name='matriz')
df_real_matriz=df_real_matriz.drop(['Unnamed: 4','Gm'],axis=1)
df_real_matriz

"""Combinado as tabelas de lâmina, fibra e matriz em um único DataFrame."""

df_real=df_real_lamina.merge(df_real_fibra,on='lamina')
df_real=df_real.merge(df_real_matriz,on='lamina')
df_real=df_real[df_real["lamina"]!=4]
df_real[75:85]

"""Realizado a divisão de X e y, sendo um y para cada propriedade, para os métodos de Regressão Linear, Árvore de Decisão e Florestas Aleatórias.

###E1
"""

E1_real=df_real.loc[:,['E1','Vf','E1f','E2f','G12f','G23f','nu12f','Em','num'	]]
E1_real=E1_real.dropna()

X_E1_real=E1_real.loc[:,['Vf','E1f','E2f','G12f','G23f','nu12f','Em','num']]
y_E1_real=E1_real.loc[:,['E1']]
len(E1_real)
y_E1_real
E1_real

X_E1_real

"""###E2"""

E2_real=df_real.loc[:,['E2','Vf','E1f','E2f','G12f','G23f','nu12f','Em','num'	]]
E2_real=E2_real.dropna()

X_E2_real=E2_real.loc[:,['Vf','E1f','E2f','G12f','G23f','nu12f','Em','num']]
y_E2_real=E2_real.loc[:,['E2']]
len(E2_real)

"""###G12"""

G12_real=df_real.loc[:,['G12','Vf','E1f','E2f','G12f','G23f','nu12f','Em','num'	]]
G12_real=G12_real.dropna()

X_G12_real=G12_real.loc[:,['Vf','E1f','E2f','G12f','G23f','nu12f','Em','num']]
y_G12_real=G12_real.loc[:,['G12']]
len(G12_real)

"""###G23"""

G23_real=df_real.loc[:,['G23','Vf','E1f','E2f','G12f','G23f','nu12f','Em','num'	]]
G23_real=G23_real.dropna()

X_G23_real=G23_real.loc[:,['Vf','E1f','E2f','G12f','G23f','nu12f','Em','num']]
y_G23_real=G23_real.loc[:,['G23']]
len(G23_real)

"""###nu12"""

nu12_real=df_real.loc[:,['nu12','Vf','E1f','E2f','G12f','G23f','nu12f','Em','num'	]]
nu12_real=nu12_real.dropna()

X_nu12_real=nu12_real.loc[:,['Vf','E1f','E2f','G12f','G23f','nu12f','Em','num']]
y_nu12_real=nu12_real.loc[:,['nu12']]
len(nu12_real)

"""Realizado a divisão de X e y, sendo um y para todas as propriedades, para as redes neurais.

###Neural Network
"""

NNW_real=df_real.loc[:,:]
NNW_real=NNW_real.dropna()

X_NNW_real=NNW_real.loc[:,['Vf','E1f','E2f','G12f','G23f','nu12f','Em','num']]
y_NNW_real=NNW_real.loc[:,['E1','E2','G12','G23','nu12']]
len(NNW_real)

"""#Metricas"""

def regression_results(y_true, y_pred):
    # Regression metrics
    explained_variance=metrics.explained_variance_score(y_true, y_pred)  # Podemos perceber que o modelo busca os valores reais de forma próxima, porém ainda 
    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred)       # é necessário obter o ajuste fino que são medidos pelos erros: MAE, MSE, RMSE 
    mse=metrics.mean_squared_error(y_true, y_pred) 
    #mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)
    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)
    r2=metrics.r2_score(y_true, y_pred)
    #print('explained_variance: ', round(explained_variance,4))  # informa quão confiável um modelo que descreve um fenômeno observado parece ser 
    #print('mean_squared_log_error: ', round(mean_squared_log_error,4)) #Logaritmo do erro quadrático médio
    #print('r2: ', round(r2,4))
    #print('MAE: ', round(mean_absolute_error,4)) # Erro médio absoluto
    #print('MSE: ', round(mse,4))              # Erro quadrático médio
    #print('RMSE: ', round(np.sqrt(mse),4))   #Erro de raiz quadrada média
    return [explained_variance,r2,mean_absolute_error,mse,np.sqrt(mse)]

def print_meticas(metricas):
  print('Métrica:   Média / Desvio Padrão')
  print('r2:   ',round(sum(metricas['R2'])/len(metricas['R2']),4),"/", round(np.std(metricas['R2']),4))
  print('MAE:   ',round(sum(metricas['MAE'])/len(metricas['MAE']),4), "/", round(np.std(metricas['MAE']),4))
  print('MSE:   ',round(sum(metricas['MSE'])/len(metricas['MSE']),4), "/", round(np.std(metricas['MSE']),4))
  print('RMSE:   ',round(sum(metricas['RMSE'])/len(metricas['RMSE']),4), "/", round(np.std(metricas['RMSE']),4))

def PE(prediction,real):
  df_aux=pd.DataFrame()
  df_aux['Prediction']=prediction
  df_aux['Real']=list(real.iloc[:,0])
  df_aux['PE']=abs(df_aux['Prediction']-df_aux['Real'])/df_aux['Real']
  print("PE: {:.2f}%".format(df_aux['PE'].mean()*100))
  return [df_aux['PE'].mean(),df_aux]

"""#Modelos Aprendizado de Máquina"""

def LR_model(X):
  model = LR()
  
  return model

def DTR_model(X,parametros):
  max_depth,random_state,max_leaf_nodes=parametros
  model= DTR(max_depth=max_depth,random_state=random_state,max_leaf_nodes=max_leaf_nodes)
  return model

def RFR_model(X,parametros):
  max_depth,random_state,max_leaf_nodes=parametros
  model= RFR(max_depth=max_depth,random_state=random_state,max_leaf_nodes=max_leaf_nodes)
  return model

"""#KFold

Função para implementar o KFold, realizando o treino e validação dos dados, para validação cruzada.
"""

def kfold(X,y,ml_model,parametros):
  n_splits=5
  cv = KFold(n_splits=n_splits, random_state=2, shuffle=True)

  

  if ml_model!="NNW":
    metricas={'R2':[],'MAE':[],'MSE':[],'RMSE':[]}
    resultados=[]

    for train_index, test_index in cv.split(X):
      
      if len(X.columns)>1:
        X_train= X.iloc[train_index[0:],:]
        X_test= X.iloc[test_index[0:],:]
      else:
        X_train= X.iloc[train_index[0:]]
        X_test= X.iloc[test_index[0:]]
      y_train= y.iloc[train_index[0:]]
      y_test=y.iloc[test_index[0:]]
      
      
      if ml_model=='LR':
        completo=LR_model(X)
      elif ml_model=="DTR":
        completo=DTR_model(X,parametros)
      elif ml_model=="RFR":
        completo=RFR_model(X,parametros)
      
      
      completo.fit(X_train, y_train)
      
      previsao=completo.predict(X_test)
      explained_variance,r2,mae,mse,rmse=regression_results(y_test, previsao)
      metricas['R2'].append(r2)
      metricas['MAE'].append(mae)
      metricas['MSE'].append(mse)
      metricas['RMSE'].append(rmse)
      resultados.append([y_test,previsao])

  ##############################################################################################

  else:
    metricas={'E1':{'R2':[],'MAE':[],'MSE':[],'RMSE':[]},'E2':{'R2':[],'MAE':[],'MSE':[],'RMSE':[]},'G12':{'R2':[],'MAE':[],'MSE':[],'RMSE':[]},'G23':{'R2':[],'MAE':[],'MSE':[],'RMSE':[]},'nu12':{'R2':[],'MAE':[],'MSE':[],'RMSE':[]}}
    contador=1
    resultados=[]

    units,Layers,dropout,min_delta,patience,L2=parametros
    Layers=Layers-1
    input_shape=[len(X.columns)]
    output_shape=len(y.columns)

    for train_index, test_index in cv.split(X):
      print(contador,"de",n_splits)
      if len(X.columns)>1:
        X_train= X.iloc[train_index,:]
        X_test= X.iloc[test_index,:]
      else:
        X_train= X.iloc[train_index]
        X_test= X.iloc[test_index]

      y_train= y.iloc[train_index,:]
      y_test=y.iloc[test_index,:]
      

      #Normalizar os dados
      scaler=MinMaxScaler()
      X_train=pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)
      X_test=pd.DataFram2e(scaler.fit_transform(X_test),columns=X_test.columns)
      

      model=keras.Sequential([layers.Dense(input_shape=input_shape,units=units,activation='relu',kernel_regularizer=keras.regularizers.l2(L2))])
      for Layer in list(range(0,Layers)):
        model.add(layers.Dropout(dropout))
        model.add(layers.Dense(units=units,activation='relu',kernel_regularizer=keras.regularizers.l2(L2)))
      model.add(layers.Dense(output_shape))

      

      model.compile(optimizer='adam',loss="mae")
      early_stopping=EarlyStopping(min_delta=min_delta,patience=patience,restore_best_weights=True)

      model.fit(X_train,y_train,
                batch_size=256,callbacks=[early_stopping], # put your callbacks in a list
                verbose=0,
                epochs=500,
                validation_split=0.2)
      previsao_NNW=model.predict(X_test)
      
      y_pred={'E1':[],'E2':[],'G12':[],'G23':[],'nu12':[]}
      y_true={'E1':[],'E2':[],'G12':[],'G23':[],'nu12':[]}
      c1=0
      while c1<len(previsao_NNW):
        y_pred['E1'].append(previsao_NNW[c1][0])
        y_true['E1'].append(y_test.iloc[c1,0])

        y_pred['E2'].append(previsao_NNW[c1][1])
        y_true['E2'].append(y_test.iloc[c1,1])

        y_pred['G12'].append(previsao_NNW[c1][2])
        y_true['G12'].append(y_test.iloc[c1,2])

        y_pred['G23'].append(previsao_NNW[c1][3])
        y_true['G23'].append(y_test.iloc[c1,3])

        y_pred['nu12'].append(previsao_NNW[c1][4])
        y_true['nu12'].append(y_test.iloc[c1,4])
        c1+=1
      

      for i in y_pred:
        lista_metricas=regression_results(y_true[i],y_pred[i])
        c=1
        for metrica in metricas[i]:
          metricas[i][metrica].append(lista_metricas[c])
          c+=1
      contador+=1
      resultados.append([y_test,y_pred])
    completo=model
    display(plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True))
  
  return [metricas,resultados,completo]

def NNW_5to1(DF):
  DF_list={"E1":[],"E2":[],"G12":[],"G23":[],"nu12":[]}
  for linha in DF:
    for c,propriedade in enumerate(DF_list):
      DF_list[propriedade].append(linha[c])

  return DF_list

"""#Convergence Analysis"""

def convergence(X,y,ml_model,parametros):
  X_train_total,X_test,y_train_total,y_test=train_test_split(X,y,train_size=0.2,random_state=2)
  X_train_old=pd.DataFrame()
  y_train_old=pd.DataFrame()

  train_size=[]
  MAEs=[]

  kf = KFold(n_splits=100, random_state=2, shuffle=True)
  

  for train_index, test_index in kf.split(X_train_total):
    if len(X.columns)>1:
      X_train= X_train_total.iloc[test_index[0:],:]
    else:
      X_train= X_train_total.iloc[test_index[0:]]
    y_train= y_train_total.iloc[test_index[0:]]
    y_train=pd.DataFrame(y_train)
    

    if ml_model=='LR':
      model=LR_model(X)
    elif ml_model=="DTR":
      model=DTR_model(X,parametros)
    elif ml_model=="RFR":
      model=RFR_model(X,parametros)
    
    
    X_train=X_train_old.append(X_train)
    y_train=y_train_old.append(y_train)


    
    model.fit(X_train,y_train)

    
    previsao=model.predict(X_test)

    explained_variance,r2,mae,mse,rmse=regression_results(y_test, previsao)
    MAEs.append(mae)
    train_size.append(len(X_train))

    
    X_train_old=X_train
    y_train_old=y_train

  return train_size,MAEs

"""#Regressão Linear"""

def pipeline_modelo(modelo):
  numeric_features = ['Vf',	'E1f',	'E2f',	'G12f',	'G23f',	'nu12f',	'Em',	'num']
  numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])
  preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])
  completo_LR = Pipeline(steps=[('preprocessor', preprocessor),
                      ('classifier', modelo )])
  return completo_LR

"""##Variável E1"""

model='LR'

metricas_E1,resultados_E1,modelo_LR_E1=kfold(X_train,y_E1_train,model,[])
print_meticas(metricas_E1)

prediction_LR_E1=modelo_LR_E1.predict(X_test)
metrics_LR_E1=regression_results(y_E1_test, prediction_LR_E1)
print(f"MAE: {metrics_LR_E1[2]:.5f}")
print(f"R2: {metrics_LR_E1[1]:.2f}")

PE_LR_E1,PE_LR_E1_list=PE(prediction_LR_E1,pd.DataFrame(y_E1_test))

"""###Real"""

prediction_LR_E1_real=modelo_LR_E1.predict(X_E1_real)
metrics_LR_E1_real=regression_results(y_E1_real, prediction_LR_E1_real)
print(f"MAE: {metrics_LR_E1_real[2]:.5f}")
print(f"R2: {metrics_LR_E1_real[1]:.2f}")

PE_LR_E1_real,PE_LR_E1_list_real=PE(prediction_LR_E1_real,y_E1_real)

"""##Variável E2"""

metricas_E2,resultados_E2,modelo_LR_E2=kfold(X,y_E2,model,[])
print_meticas(metricas_E2)

prediction_LR_E2=modelo_LR_E2.predict(X_test)
metrics_LR_E2=regression_results(y_E2_test, prediction_LR_E2)
print(f"MAE: {metrics_LR_E2[2]:.5f}")
print(f"R2: {metrics_LR_E2[1]:.2f}")

PE_LR_E2,PE_LR_E2_list=PE(prediction_LR_E2,pd.DataFrame(y_E2_test))

"""###Real"""

prediction_LR_E2_real=modelo_LR_E2.predict(X_E2_real)
metrics_LR_E2_real=regression_results(y_E2_real, prediction_LR_E2_real)
print(f"MAE: {metrics_LR_E2_real[2]:.5f}")
print(f"R2: {metrics_LR_E2_real[1]:.2f}")

PE_LR_E2_real,PE_LR_E2_list_real=PE(prediction_LR_E2_real,y_E2_real)


"""##Variável G12"""

metricas_G12,resultados_G12,modelo_LR_G12=kfold(X,y_G12,model,[])
print_meticas(metricas_G12)

prediction_LR_G12=modelo_LR_G12.predict(X_test)
metrics_LR_G12=regression_results(y_G12_test, prediction_LR_G12)
print(f"MAE: {metrics_LR_G12[2]:.5f}")
print(f"R2: {metrics_LR_G12[1]:.2f}")

PE_LR_G12,PE_LR_G12_list=PE(prediction_LR_G12,pd.DataFrame(y_G12_test))

"""###Real"""

prediction_LR_G12_real=modelo_LR_G12.predict(X_G12_real)
metrics_LR_G12_real=regression_results(y_G12_real, prediction_LR_G12_real)
print(f"MAE: {metrics_LR_G12_real[2]:.5f}")
print(f"R2: {metrics_LR_G12_real[1]:.2f}")

PE_LR_G12_real,PE_LR_G12_list_real=PE(prediction_LR_G12_real,y_G12_real)


"""##Variável G23"""

metricas_G23,resultados_G23,modelo_LR_G23=kfold(X,y_G23,model,[])
print_meticas(metricas_G23)

prediction_LR_G23=modelo_LR_G23.predict(X_test)
metrics_LR_G23=regression_results(y_G23_test, prediction_LR_G23)
print(f"MAE: {metrics_LR_G23[2]:.5f}")
print(f"R2: {metrics_LR_G23[1]:.2f}")

PE_LR_G23,PE_LR_G23_list=PE(prediction_LR_G23,pd.DataFrame(y_G23_test))

"""###Real"""

prediction_LR_G23_real=modelo_LR_G23.predict(X_G23_real)
metrics_LR_G23_real=regression_results(y_G23_real, prediction_LR_G23_real)
print(f"MAE: {metrics_LR_G23_real[2]:.5f}")
print(f"R2: {metrics_LR_G23_real[1]:.2f}")

PE_LR_G23_real,PE_LR_G23_list_real=PE(prediction_LR_G23_real,y_G23_real)


"""##Variável nu12"""

metricas_nu12,resultados_nu12,modelo_LR_nu12=kfold(X,y_nu12,model,[])
print_meticas(metricas_nu12)

prediction_LR_nu12=modelo_LR_nu12.predict(X_test)
metrics_LR_nu12=regression_results(y_nu12_test, prediction_LR_nu12)
print(f"MAE: {metrics_LR_nu12[2]:.5f}")
print(f"R2: {metrics_LR_nu12[1]:.2f}")

PE_LR_nu12,PE_LR_nu12_list=PE(prediction_LR_nu12,pd.DataFrame(y_nu12_test))

"""###Real"""

prediction_LR_nu12_real=modelo_LR_nu12.predict(X_nu12_real)
metrics_LR_nu12_real=regression_results(y_nu12_real, prediction_LR_nu12_real)
print(f"MAE: {metrics_LR_nu12_real[2]:.5f}")
print(f"R2: {metrics_LR_nu12_real[1]:.2f}")

PE_LR_nu12_real,PE_LR_nu12_list_real=PE(prediction_LR_nu12_real,y_nu12_real)


"""#Hyperparameters Search"""

improv_perc=0.01

"""##Decision Tree

###E1
"""

df_metricas_DTR_E1=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_DTR_E1=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model='DTR'
  metricas_E1,resultados_E1,model_DTR_E1=kfold(X_train,y_E1_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_E1['R2'])/len(metricas_E1['R2'])
  mae=sum(metricas_E1['MAE'])/len(metricas_E1['MAE'])
  mse=sum(metricas_E1['MSE'])/len(metricas_E1['MSE'])
  rmse=sum(metricas_E1['RMSE'])/len(metricas_E1['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_DTR_E1=max_depth

  df_metricas_DTR_E1.loc[linha,'Max Depth']=max_depth
  df_metricas_DTR_E1.loc[linha,'R2']=r2
  df_metricas_DTR_E1.loc[linha,'MAE']=mae
  df_metricas_DTR_E1.loc[linha,'MSE']=mse
  df_metricas_DTR_E1.loc[linha,'RMSE']=rmse
  linha+=1

  models_DTR_E1.append(model_DTR_E1)
print(df_metricas_DTR_E1,'\n'*5,best_max_depth_DTR_E1)

best_model_DTR_E1=models_DTR_E1[df_metricas_DTR_E1[df_metricas_DTR_E1['Max Depth']==best_max_depth_DTR_E1].index[0]]

"""####Feature Importance"""

imp = best_model_DTR_E1.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])

plt.show()

"""####Metrics"""

prediction_DTR_E1=best_model_DTR_E1.predict(X_test)
metrics_DTR_E1=regression_results(y_E1_test, prediction_DTR_E1)
print(f"MAE: {metrics_DTR_E1[2]:.5f}")

print(f"R2: {metrics_DTR_E1[1]:.2f}")

PE_DTR_E1,PE_DTR_E1_list=PE(prediction_DTR_E1,pd.DataFrame(y_E1_test))

"""####Convergence"""

train_size_DTR_E1,MAEs_DTR_E1=convergence(X,y_E1,"DTR",[best_max_depth_DTR_E1,random_state,max_leaf_nodes])

plt.plot(train_size_DTR_E1,MAEs_DTR_E1)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_DTR_E1_real=best_model_DTR_E1.predict(X_E1_real)
metrics_DTR_E1_real=regression_results(y_E1_real, prediction_DTR_E1_real)
print(f"MAE: {metrics_DTR_E1_real[2]:.5f}")

print(f"R2: {metrics_DTR_E1_real[1]:.2f}")

PE_DTR_E1,PE_DTR_E1_list=PE(prediction_DTR_E1_real,y_E1_real)

plt.boxplot(PE_DTR_E1_list['PE'])



PE_DTR_E1_list

"""###E2"""

df_metricas_DTR_E2=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_DTR_E2=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model='DTR'
  metricas_E2,resultados_E2,model_DTR_E2=kfold(X_train,y_E2_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_E2['R2'])/len(metricas_E2['R2'])
  mae=sum(metricas_E2['MAE'])/len(metricas_E2['MAE'])
  mse=sum(metricas_E2['MSE'])/len(metricas_E2['MSE'])
  rmse=sum(metricas_E2['RMSE'])/len(metricas_E2['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_DTR_E2=max_depth

  df_metricas_DTR_E2.loc[linha,'Max Depth']=max_depth
  df_metricas_DTR_E2.loc[linha,'R2']=r2
  df_metricas_DTR_E2.loc[linha,'MAE']=mae
  df_metricas_DTR_E2.loc[linha,'MSE']=mse
  df_metricas_DTR_E2.loc[linha,'RMSE']=rmse
  linha+=1

  models_DTR_E2.append(model_DTR_E2)
print(df_metricas_DTR_E2,'\n'*5,best_max_depth_DTR_E2)

best_model_DTR_E2=models_DTR_E2[df_metricas_DTR_E2[df_metricas_DTR_E2['Max Depth']==best_max_depth_DTR_E2].index[0]]

"""####Feature Importance"""

imp = best_model_DTR_E2.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.show()

"""####Metrics"""

prediction_DTR_E2=best_model_DTR_E2.predict(X_test)
metrics_DTR_E2=regression_results(y_E2_test, prediction_DTR_E2)
print(f"MAE: {metrics_DTR_E2[2]:.5f}")

print(f"R2: {metrics_DTR_E2[1]:.2f}")

PE_DTR_E2,PE_DTR_E2_list=PE(prediction_DTR_E2,pd.DataFrame(y_E2_test))

"""####Convergence"""

train_size_DTR_E2,MAEs_DTR_E2=convergence(X,y_E2,"DTR",[best_max_depth_DTR_E2,random_state,max_leaf_nodes])

plt.plot(train_size_DTR_E2,MAEs_DTR_E2)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_DTR_E2_real=best_model_DTR_E2.predict(X_E2_real)
metrics_DTR_E2_real=regression_results(y_E2_real, prediction_DTR_E2_real)
print(f"MAE: {metrics_DTR_E2_real[2]:.5f}")

print(f"R2: {metrics_DTR_E2_real[1]:.2f}")

PE_DTR_E2,PE_DTR_E2_list=PE(prediction_DTR_E2_real,y_E2_real)

PE_DTR_E2_list

"""###G12"""

df_metricas_DTR_G12=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_DTR_G12=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model='DTR'
  metricas_G12,resultados_G12,model_DTR_G12=kfold(X_train,y_G12_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_G12['R2'])/len(metricas_G12['R2'])
  mae=sum(metricas_G12['MAE'])/len(metricas_G12['MAE'])
  mse=sum(metricas_G12['MSE'])/len(metricas_G12['MSE'])
  rmse=sum(metricas_G12['RMSE'])/len(metricas_G12['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_DTR_G12=max_depth

  df_metricas_DTR_G12.loc[linha,'Max Depth']=max_depth
  df_metricas_DTR_G12.loc[linha,'R2']=r2
  df_metricas_DTR_G12.loc[linha,'MAE']=mae
  df_metricas_DTR_G12.loc[linha,'MSE']=mse
  df_metricas_DTR_G12.loc[linha,'RMSE']=rmse
  linha+=1

  models_DTR_G12.append(model_DTR_G12)
print(df_metricas_DTR_G12,'\n'*5,best_max_depth_DTR_G12)

best_model_DTR_G12=models_DTR_G12[df_metricas_DTR_G12[df_metricas_DTR_G12['Max Depth']==best_max_depth_DTR_G12].index[0]]

"""####Feature Importance"""

imp = best_model_DTR_G12.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.show()

"""####Metrics"""

prediction_DTR_G12=best_model_DTR_G12.predict(X_test)
metrics_DTR_G12=regression_results(y_G12_test, prediction_DTR_G12)
print(f"MAE: {metrics_DTR_G12[2]:.5f}")

print(f"R2: {metrics_DTR_G12[1]:.2f}")

PE_DTR_G12,PE_DTR_G12_list=PE(prediction_DTR_G12,pd.DataFrame(y_G12_test))

"""####Convergence"""

train_size_DTR_G12,MAEs_DTR_G12=convergence(X,y_G12,"DTR",[best_max_depth_DTR_G12,random_state,max_leaf_nodes])

plt.plot(train_size_DTR_G12,MAEs_DTR_G12)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_DTR_G12_real=best_model_DTR_G12.predict(X_G12_real)
metrics_DTR_G12_real=regression_results(y_G12_real, prediction_DTR_G12_real)
print(f"MAE: {metrics_DTR_G12_real[2]:.5f}")

print(f"R2: {metrics_DTR_G12_real[1]:.2f}")

PE_DTR_G12,PE_DTR_G12_list=PE(prediction_DTR_G12_real,y_G12_real)

PE_DTR_G12_list

"""###G23"""

df_metricas_DTR_G23=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_DTR_G23=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model='DTR'
  metricas_G23,resultados_G23,model_DTR_G23=kfold(X_train,y_G23_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_G23['R2'])/len(metricas_G23['R2'])
  mae=sum(metricas_G23['MAE'])/len(metricas_G23['MAE'])
  mse=sum(metricas_G23['MSE'])/len(metricas_G23['MSE'])
  rmse=sum(metricas_G23['RMSE'])/len(metricas_G23['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_DTR_G23=max_depth

  df_metricas_DTR_G23.loc[linha,'Max Depth']=max_depth
  df_metricas_DTR_G23.loc[linha,'R2']=r2
  df_metricas_DTR_G23.loc[linha,'MAE']=mae
  df_metricas_DTR_G23.loc[linha,'MSE']=mse
  df_metricas_DTR_G23.loc[linha,'RMSE']=rmse
  linha+=1
  models_DTR_G23.append(model_DTR_G23)
print(df_metricas_DTR_G23,'\n'*5,best_max_depth_DTR_G23)

best_model_DTR_G23=models_DTR_G23[df_metricas_DTR_G23[df_metricas_DTR_G23['Max Depth']==best_max_depth_DTR_G23].index[0]]

"""####Feature Importance"""

imp = best_model_DTR_G23.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.show()

"""####Metrics"""

prediction_DTR_G23=best_model_DTR_G23.predict(X_test)
metrics_DTR_G23=regression_results(y_G23_test, prediction_DTR_G23)
print(f"MAE: {metrics_DTR_G23[2]:.5f}")

print(f"R2: {metrics_DTR_G23[1]:.2f}")

PE_DTR_G23,PE_DTR_G23_list=PE(prediction_DTR_G23,pd.DataFrame(y_G23_test))

"""####Convergence"""

train_size_DTR_G23,MAEs_DTR_G23=convergence(X,y_G23,"DTR",[best_max_depth_DTR_G23,random_state,max_leaf_nodes])

plt.plot(train_size_DTR_G23,MAEs_DTR_G23)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_DTR_G23_real=best_model_DTR_G23.predict(X_G23_real)
metrics_DTR_G23_real=regression_results(y_G23_real, prediction_DTR_G23_real)
print(f"MAE: {metrics_DTR_G23_real[2]:.5f}")

print(f"R2: {metrics_DTR_G23_real[1]:.2f}")

PE_DTR_G23,PE_DTR_G23_list=PE(prediction_DTR_G23_real,y_G23_real)

"""###nu12"""

df_metricas_DTR_nu12=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_DTR_nu12=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model='DTR'
  metricas_nu12,resultados_nu12,model_DTR_nu12=kfold(X_train,y_nu12_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_nu12['R2'])/len(metricas_nu12['R2'])
  mae=sum(metricas_nu12['MAE'])/len(metricas_nu12['MAE'])
  mse=sum(metricas_nu12['MSE'])/len(metricas_nu12['MSE'])
  rmse=sum(metricas_nu12['RMSE'])/len(metricas_nu12['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_DTR_nu12=max_depth

  df_metricas_DTR_nu12.loc[linha,'Max Depth']=max_depth
  df_metricas_DTR_nu12.loc[linha,'R2']=r2
  df_metricas_DTR_nu12.loc[linha,'MAE']=mae
  df_metricas_DTR_nu12.loc[linha,'MSE']=mse
  df_metricas_DTR_nu12.loc[linha,'RMSE']=rmse
  linha+=1
  models_DTR_nu12.append(model_DTR_nu12)
print(df_metricas_DTR_nu12,'\n'*5,best_max_depth_DTR_nu12)
best_model_DTR_nu12=models_DTR_nu12[df_metricas_DTR_nu12[df_metricas_DTR_nu12['Max Depth']==best_max_depth_DTR_nu12].index[0]]

"""####Feature Importance"""

imp = best_model_DTR_nu12.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.show()

auxiliar=pd.DataFrame(resultados_nu12[1][1],columns=['Previsão'],index=resultados_nu12[1][0].index)
auxiliar['Gabarito']=resultados_nu12[1][0]
auxiliar['Erro %']=(abs(auxiliar['Previsão']-auxiliar['Gabarito'])/auxiliar['Gabarito'])*100

print("{:.2f}%".format(auxiliar['Erro %'].mean()))

"""####Metrics"""

prediction_DTR_nu12=best_model_DTR_nu12.predict(X_test)
metrics_DTR_nu12=regression_results(y_nu12_test, prediction_DTR_nu12)
print(f"MAE: {metrics_DTR_nu12[2]:.5f}")

print(f"R2: {metrics_DTR_nu12[1]:.2f}")

PE_DTR_nu12,PE_DTR_nu12_list=PE(prediction_DTR_nu12,pd.DataFrame(y_nu12_test))

"""####Convergence"""

train_size_DTR_nu12,MAEs_DTR_nu12=convergence(X,y_nu12,"DTR",[best_max_depth_DTR_nu12,random_state,max_leaf_nodes])

plt.plot(train_size_DTR_nu12,MAEs_DTR_nu12)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_DTR_nu12_real=best_model_DTR_nu12.predict(X_nu12_real)
metrics_DTR_nu12_real=regression_results(y_nu12_real, prediction_DTR_nu12_real)
print(f"MAE: {metrics_DTR_nu12_real[2]:.5f}")

print(f"R2: {metrics_DTR_nu12_real[1]:.2f}")

PE_DTR_nu12,PE_DTR_nu12_list=PE(prediction_DTR_nu12_real,y_nu12_real)

"""###Saving Sheet"""
metricas_DTR_path=os.path.join(root_path,"Metricas","Metricas Decision Tree.xlsx")

with pd.ExcelWriter(metricas_DTR_path) as writer:
  df_metricas_DTR_E1.to_excel(writer,index=False,sheet_name="E1")
  df_metricas_DTR_E2.to_excel(writer,index=False,sheet_name="E2")
  df_metricas_DTR_G12.to_excel(writer,index=False,sheet_name="G12")
  df_metricas_DTR_G23.to_excel(writer,index=False,sheet_name="G23")
  df_metricas_DTR_nu12.to_excel(writer,index=False,sheet_name="nu12")

"""##Random Forests

###E1
"""

df_metricas_RFR_E1=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_RFR_E1=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model="RFR"
  metricas_E1,resultados_E1,model_RFR_E1=kfold(X_train,y_E1_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_E1['R2'])/len(metricas_E1['R2'])
  mae=sum(metricas_E1['MAE'])/len(metricas_E1['MAE'])
  mse=sum(metricas_E1['MSE'])/len(metricas_E1['MSE'])
  rmse=sum(metricas_E1['RMSE'])/len(metricas_E1['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_RFR_E1=max_depth

  df_metricas_RFR_E1.loc[linha,'Max Depth']=max_depth
  df_metricas_RFR_E1.loc[linha,'R2']=r2
  df_metricas_RFR_E1.loc[linha,'MAE']=mae
  df_metricas_RFR_E1.loc[linha,'MSE']=mse
  df_metricas_RFR_E1.loc[linha,'RMSE']=rmse
  linha+=1
  models_RFR_E1.append(model_RFR_E1)
print(df_metricas_RFR_E1,'\n'*5,best_max_depth_RFR_E1)
best_model_RFR_E1=models_RFR_E1[df_metricas_RFR_E1[df_metricas_RFR_E1['Max Depth']==best_max_depth_RFR_E1].index[0]]

"""####Feature Importance"""

imp = best_model_RFR_E1.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.show()

"""####Metrics"""

prediction_RFR_E1=best_model_RFR_E1.predict(X_test)
metrics_RFR_E1=regression_results(y_E1_test, prediction_RFR_E1)
print(f"MAE: {metrics_RFR_E1[2]:.5f}")

print(f"R2: {metrics_RFR_E1[1]:.2f}")

PE_RFR_E1,PE_RFR_E1_list=PE(prediction_RFR_E1,pd.DataFrame(y_E1_test))

"""####Convergence"""

train_size_RFR_E1,MAEs_RFR_E1=convergence(X,y_E1,"RFR",[best_max_depth_RFR_E1,random_state,max_leaf_nodes])

plt.plot(train_size_RFR_E1,MAEs_RFR_E1)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_RFR_E1_real=best_model_RFR_E1.predict(X_E1_real)
metrics_RFR_E1_real=regression_results(y_E1_real, prediction_RFR_E1_real)
print(f"MAE: {metrics_RFR_E1_real[2]:.5f}")

print(f"R2: {metrics_RFR_E1_real[1]:.2f}")

PE_RFR_E1,PE_RFR_E1_list=PE(prediction_RFR_E1_real,y_E1_real)

"""###E2"""

df_metricas_RFR_E2=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_RFR_E2=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model='RFR'
  metricas_E2,resultados_E2,model_RFR_E2=kfold(X_train,y_E2_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_E2['R2'])/len(metricas_E2['R2'])
  mae=sum(metricas_E2['MAE'])/len(metricas_E2['MAE'])
  mse=sum(metricas_E2['MSE'])/len(metricas_E2['MSE'])
  rmse=sum(metricas_E2['RMSE'])/len(metricas_E2['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_RFR_E2=max_depth

  df_metricas_RFR_E2.loc[linha,'Max Depth']=max_depth
  df_metricas_RFR_E2.loc[linha,'R2']=r2
  df_metricas_RFR_E2.loc[linha,'MAE']=mae
  df_metricas_RFR_E2.loc[linha,'MSE']=mse
  df_metricas_RFR_E2.loc[linha,'RMSE']=rmse
  linha+=1
  models_RFR_E2.append(model_RFR_E2)
print(df_metricas_RFR_E2,'\n'*5,best_max_depth_RFR_E2)
best_model_RFR_E2=models_RFR_E2[df_metricas_RFR_E2[df_metricas_RFR_E2['Max Depth']==best_max_depth_RFR_E2].index[0]]

"""####Feature Importance"""

imp = best_model_RFR_E2.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.show()

"""####Metrics"""

prediction_RFR_E2=best_model_RFR_E2.predict(X_test)
metrics_RFR_E2=regression_results(y_E2_test, prediction_RFR_E2)
print(f"MAE: {metrics_RFR_E2[2]:.5f}")

print(f"R2: {metrics_RFR_E2[1]:.2f}")

PE_RFR_E2,PE_RFR_E2_list=PE(prediction_RFR_E2,pd.DataFrame(y_E2_test))

"""####Convergence"""

train_size_RFR_E2,MAEs_RFR_E2=convergence(X,y_E2,"RFR",[best_max_depth_RFR_E2,random_state,max_leaf_nodes])

plt.plot(train_size_RFR_E2,MAEs_RFR_E2)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_RFR_E2_real=best_model_RFR_E2.predict(X_E2_real)
metrics_RFR_E2_real=regression_results(y_E2_real, prediction_RFR_E2_real)
print(f"MAE: {metrics_RFR_E2_real[2]:.5f}")

print(f"R2: {metrics_RFR_E2_real[1]:.2f}")

PE_RFR_E2,PE_RFR_E2_list=PE(prediction_RFR_E2_real,y_E2_real)

"""###G12"""

df_metricas_RFR_G12=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_RFR_G12=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model='RFR'
  metricas_G12,resultados_G12,model_RFR_G12=kfold(X_train,y_G12_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_G12['R2'])/len(metricas_G12['R2'])
  mae=sum(metricas_G12['MAE'])/len(metricas_G12['MAE'])
  mse=sum(metricas_G12['MSE'])/len(metricas_G12['MSE'])
  rmse=sum(metricas_G12['RMSE'])/len(metricas_G12['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_RFR_G12=max_depth

  df_metricas_RFR_G12.loc[linha,'Max Depth']=max_depth
  df_metricas_RFR_G12.loc[linha,'R2']=r2
  df_metricas_RFR_G12.loc[linha,'MAE']=mae
  df_metricas_RFR_G12.loc[linha,'MSE']=mse
  df_metricas_RFR_G12.loc[linha,'RMSE']=rmse
  linha+=1
  models_RFR_G12.append(model_RFR_G12)
print(df_metricas_RFR_G12,'\n'*5,best_max_depth_RFR_G12)
best_model_RFR_G12=models_RFR_G12[df_metricas_RFR_G12[df_metricas_RFR_G12['Max Depth']==best_max_depth_RFR_G12].index[0]]

"""####Feature Importance"""

imp = best_model_RFR_G12.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.show()

"""####Metrics"""

prediction_RFR_G12=best_model_RFR_G12.predict(X_test)
metrics_RFR_G12=regression_results(y_G12_test, prediction_RFR_G12)
print(f"MAE: {metrics_RFR_G12[2]:.5f}")

print(f"R2: {metrics_RFR_G12[1]:.2f}")

PE_RFR_G12,PE_RFR_G12_list=PE(prediction_RFR_G12,pd.DataFrame(y_G12_test))

"""####Convergence"""

train_size_RFR_G12,MAEs_RFR_G12=convergence(X,y_G12,"RFR",[best_max_depth_RFR_G12,random_state,max_leaf_nodes])

plt.plot(train_size_RFR_G12,MAEs_RFR_G12)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_RFR_G12_real=best_model_RFR_G12.predict(X_G12_real)
metrics_RFR_G12_real=regression_results(y_G12_real, prediction_RFR_G12_real)
print(f"MAE: {metrics_RFR_G12_real[2]:.5f}")

print(f"R2: {metrics_RFR_G12_real[1]:.2f}")

PE_RFR_G12,PE_RFR_G12_list=PE(prediction_RFR_G12_real,y_G12_real)

"""###G23"""

df_metricas_RFR_G23=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_RFR_G23=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model='RFR'
  metricas_G23,resultados_G23,model_RFR_G23=kfold(X_train,y_G23_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_G23['R2'])/len(metricas_G23['R2'])
  mae=sum(metricas_G23['MAE'])/len(metricas_G23['MAE'])
  mse=sum(metricas_G23['MSE'])/len(metricas_G23['MSE'])
  rmse=sum(metricas_G23['RMSE'])/len(metricas_G23['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_RFR_G23=max_depth

  df_metricas_RFR_G23.loc[linha,'Max Depth']=max_depth
  df_metricas_RFR_G23.loc[linha,'R2']=r2
  df_metricas_RFR_G23.loc[linha,'MAE']=mae
  df_metricas_RFR_G23.loc[linha,'MSE']=mse
  df_metricas_RFR_G23.loc[linha,'RMSE']=rmse
  linha+=1
  models_RFR_G23.append(model_RFR_G23)
print(df_metricas_RFR_G23,'\n'*5,best_max_depth_RFR_G23)
best_model_RFR_G23=models_RFR_G23[df_metricas_RFR_G23[df_metricas_RFR_G23['Max Depth']==best_max_depth_RFR_G23].index[0]]

"""####Feature Importance"""

imp = best_model_RFR_G23.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.show()

"""####Metrics"""

prediction_RFR_G23=best_model_RFR_G23.predict(X_test)
metrics_RFR_G23=regression_results(y_G23_test, prediction_RFR_G23)
print(f"MAE: {metrics_RFR_G23[2]:.5f}")

print(f"R2: {metrics_RFR_G23[1]:.2f}")

PE_RFR_G23,PE_RFR_G23_list=PE(prediction_RFR_G23,pd.DataFrame(y_G23_test))

"""####Convergence"""

train_size_RFR_G23,MAEs_RFR_G23=convergence(X,y_G23,"RFR",[best_max_depth_RFR_G23,random_state,max_leaf_nodes])

plt.plot(train_size_RFR_G23,MAEs_RFR_G23)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_RFR_G23_real=best_model_RFR_G23.predict(X_G23_real)
metrics_RFR_G23_real=regression_results(y_G23_real, prediction_RFR_G23_real)
print(f"MAE: {metrics_RFR_G23_real[2]:.5f}")

print(f"R2: {metrics_RFR_G23_real[1]:.2f}")

PE_RFR_G23,PE_RFR_G23_list=PE(prediction_RFR_G23_real,y_G23_real)

"""###nu12"""

df_metricas_RFR_nu12=pd.DataFrame(columns=["Max Depth","R2","MAE","MSE","RMSE"])

max_depth_list=[5,10,20,40]
random_state=2
max_leaf_nodes=None
models_RFR_nu12=[]

mae=1000

linha=0
for max_depth in max_depth_list:
  previous_mae=mae
  model='RFR'
  metricas_nu12,resultados_nu12,model_RFR_nu12=kfold(X_train,y_nu12_train,model,[max_depth,random_state,max_leaf_nodes])
  r2=sum(metricas_nu12['R2'])/len(metricas_nu12['R2'])
  mae=sum(metricas_nu12['MAE'])/len(metricas_nu12['MAE'])
  mse=sum(metricas_nu12['MSE'])/len(metricas_nu12['MSE'])
  rmse=sum(metricas_nu12['RMSE'])/len(metricas_nu12['RMSE'])

  if (previous_mae-mae)/previous_mae>improv_perc:
    best_max_depth_RFR_nu12=max_depth

  df_metricas_RFR_nu12.loc[linha,'Max Depth']=max_depth
  df_metricas_RFR_nu12.loc[linha,'R2']=r2
  df_metricas_RFR_nu12.loc[linha,'MAE']=mae
  df_metricas_RFR_nu12.loc[linha,'MSE']=mse
  df_metricas_RFR_nu12.loc[linha,'RMSE']=rmse
  linha+=1
  models_RFR_nu12.append(model_RFR_nu12)
print(df_metricas_RFR_nu12,'\n'*5,best_max_depth_RFR_nu12)
best_model_RFR_nu12=models_RFR_nu12[df_metricas_RFR_nu12[df_metricas_RFR_nu12['Max Depth']==best_max_depth_RFR_nu12].index[0]]

"""####Feature Importance"""

imp = best_model_RFR_nu12.feature_importances_
features = X.columns
indices = np.argsort(imp)
plt.title('Importância das Caraterísticas')
plt.xlabel('Importância Relativa')
plt.barh(range(len(indices)), imp[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.show()

"""####Metrics"""

prediction_RFR_nu12=best_model_RFR_nu12.predict(X_test)
metrics_RFR_nu12=regression_results(y_nu12_test, prediction_RFR_nu12)
print(f"MAE: {metrics_RFR_nu12[2]:.5f}")

print(f"R2: {metrics_RFR_nu12[1]:.2f}")

PE_RFR_nu12,PE_RFR_nu12_list=PE(prediction_RFR_nu12,pd.DataFrame(y_nu12_test))

"""####Convergence"""

train_size_RFR_nu12,MAEs_RFR_nu12=convergence(X,y_nu12,"RFR",[best_max_depth_RFR_nu12,random_state,max_leaf_nodes])

plt.plot(train_size_RFR_nu12,MAEs_RFR_nu12)
plt.xlabel('Quantidade de Exemplos no Treino')
plt.ylabel('Erro Médio Absoluto')
plt.show()

"""####Real"""

prediction_RFR_nu12_real=best_model_RFR_nu12.predict(X_nu12_real)
metrics_RFR_nu12_real=regression_results(y_nu12_real, prediction_RFR_nu12_real)
print(f"MAE: {metrics_RFR_nu12_real[2]:.5f}")

print(f"R2: {metrics_RFR_nu12_real[1]:.2f}")

PE_RFR_nu12,PE_RFR_nu12_list=PE(prediction_RFR_nu12_real,y_nu12_real)

"""###Saving Sheet"""
metricas_RFR_path=os.path.join(root_path,"Metricas","Metricas Random Forest.xlsx")

with pd.ExcelWriter(metricas_RFR_path) as writer:
  df_metricas_RFR_E1.to_excel(writer,index=False,sheet_name="E1")
  df_metricas_RFR_E2.to_excel(writer,index=False,sheet_name="E2")
  df_metricas_RFR_G12.to_excel(writer,index=False,sheet_name="G12")
  df_metricas_RFR_G23.to_excel(writer,index=False,sheet_name="G23")
  df_metricas_RFR_nu12.to_excel(writer,index=False,sheet_name="nu12")

"""##Neural Network"""

input_shape=[len(X.columns)]
dropout=0.5
output_shape=5
L2=0.01

min_delta=0.001
patience=10

df_metricas_NNW_E1=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])
df_metricas_NNW_E2=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])
df_metricas_NNW_G12=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])
df_metricas_NNW_G23=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])
df_metricas_NNW_nu12=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])

metricas={'E1':df_metricas_NNW_E1,'E2':df_metricas_NNW_E2,'G12':df_metricas_NNW_G12,'G23':df_metricas_NNW_G23,'nu12':df_metricas_NNW_nu12}
models_NNW=[]

neurons=[50,100,200,400,600,800,1000]
Layers=[1,2,4]

linha=0
mae=10000

for Layer in Layers:
  previous_mae=mae
  for units in neurons:
    #Modelo
    model="NNW"
    metricas_NNW,resultados_NNW,model_NNW=kfold(X_train,y_NNW_train,model,[units,Layer,dropout,min_delta,patience,L2])

    #Obtendo as metricas
    mae=0
    for propriedade in metricas:
      metricas[propriedade].loc[linha,"Layers"]=Layer
      metricas[propriedade].loc[linha,"Neurons"]=units
      for metrica in ["R2","MAE","MSE","RMSE"]:
        metricas[propriedade].loc[linha,metrica]=sum(metricas_NNW[propriedade][metrica])/len(metricas_NNW[propriedade][metrica])
        if metrica=="MAE":
          mae+=sum(metricas_NNW[propriedade][metrica])/len(metricas_NNW[propriedade][metrica])
    mae=mae/len(metricas)

    if (previous_mae-mae)/previous_mae>improv_perc:
      best_index=linha

    models_NNW.append(model_NNW)
    print(metricas["E1"])
    linha+=1
    print(linha,"de",len(neurons)*len(Layers))
    
  
best_model_NNW=models_NNW[best_index]

df_metricas_NNW_E1=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])
df_metricas_NNW_E2=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])
df_metricas_NNW_G12=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])
df_metricas_NNW_G23=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])
df_metricas_NNW_nu12=pd.DataFrame(columns=["Layers","Neurons","R2","MAE","MSE","RMSE"])

metricas={'E1':df_metricas_NNW_E1,'E2':df_metricas_NNW_E2,'G12':df_metricas_NNW_G12,'G23':df_metricas_NNW_G23,'nu12':df_metricas_NNW_nu12}
models_NNW=[]

neurons=[600,800,1000]
Layers=[4]

linha=0
mae=10000

for Layer in Layers:
  previous_mae=mae
  for units in neurons:
    #Modelo
    model="NNW"
    metricas_NNW,resultados_NNW,model_NNW=kfold(X_train,y_NNW_train,model,[units,Layer,dropout,min_delta,patience,L2])

    #Obtendo as metricas
    mae=0
    for propriedade in metricas:
      metricas[propriedade].loc[linha,"Layers"]=Layer
      metricas[propriedade].loc[linha,"Neurons"]=units
      for metrica in ["R2","MAE","MSE","RMSE"]:
        metricas[propriedade].loc[linha,metrica]=sum(metricas_NNW[propriedade][metrica])/len(metricas_NNW[propriedade][metrica])
        if metrica=="MAE":
          mae+=sum(metricas_NNW[propriedade][metrica])/len(metricas_NNW[propriedade][metrica])
    mae=mae/len(metricas)

    if (previous_mae-mae)/previous_mae>improv_perc:
      best_index=linha

    models_NNW.append(model_NNW)
    print(metricas["E1"])
    linha+=1
    print(linha,"de",len(neurons)*len(Layers))
    
  
best_model_NNW=models_NNW[best_index]

"""###Saving Sheet"""


metricas_NNW_path=os.path.join(root_path,"Metricas","Metricas Neural Network.xlsx")

with pd.ExcelWriter(metricas_NNW_path) as writer:
  df_metricas_NNW_E1.to_excel(writer,index=False,sheet_name="E1")
  df_metricas_NNW_E2.to_excel(writer,index=False,sheet_name="E2")
  df_metricas_NNW_G12.to_excel(writer,index=False,sheet_name="G12")
  df_metricas_NNW_G23.to_excel(writer,index=False,sheet_name="G23")
  df_metricas_NNW_nu12.to_excel(writer,index=False,sheet_name="nu12")

"""###Metrics"""

model="NNW"
units=600
Layer=1

scaler=MinMaxScaler()
X_train=pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)
X_test=pd.DataFrame(scaler.fit_transform(X_test),columns=X_test.columns)

metricas_NNW,resultados_NNW,model_NNW=kfold(X_train,y_NNW_train,model,[units,Layer,dropout,min_delta,patience,L2])

y_NNW_train

model_NNW.predict(X_test)

prediction_NNW=model_NNW.predict(X_test)
prediction_NNW_list=NNW_5to1(prediction_NNW)
true_NNW_list=NNW_5to1(pd.DataFrame.to_numpy(y_NNW_test))
true_NNW_list

for propriedade in prediction_NNW_list:
  print(propriedade)
  metrics_NNW=regression_results(true_NNW_list[propriedade], prediction_NNW_list[propriedade])
  print(f"MAE: {metrics_NNW[2]:.5f}")
  print(f"R2: {metrics_NNW[1]:.2f}")
  PE_NNW,PE_NNW_list=PE(prediction_NNW_list[propriedade],pd.DataFrame(true_NNW_list[propriedade]))
  print('\n')

"""####Real"""

X_NNW_real=pd.DataFrame(scaler.fit_transform(X_NNW_real),columns=X_NNW_real.columns)
prediction_NNW_real=model_NNW.predict(X_NNW_real)
prediction_NNW_list_real=NNW_5to1(prediction_NNW_real)
true_NNW_list_real=NNW_5to1(pd.DataFrame.to_numpy(y_NNW_real))

for propriedade in prediction_NNW_list_real:
  print(propriedade)
  metrics_NNW_real=regression_results(true_NNW_list_real[propriedade], prediction_NNW_list_real[propriedade])
  print(f"MAE: {metrics_NNW_real[2]:.5f}")
  print(f"R2: {metrics_NNW_real[1]:.2f}")
  PE_NNW,PE_NNW_list=PE(prediction_NNW_list_real[propriedade],pd.DataFrame(true_NNW_list_real[propriedade]))
  print('\n')